\section{Compression Related Tasks}


\subsection{Text Compression as Translation}


{The first compression system that will be discussed is from the article Lexicalized Markov Grammars for Sentence Compression by \citet{galley2007lexicalized}.  This system builds on previously successful noisy channel model approaches like that from  which model the deletion problem as a kind of translation from a  the noisy channel model described in \citet{Knight:2002:SBS:604203.604207} syntax driven approaches such as that used by \citet{  is a syntax driven approach which represents rules for deletion as grammar rules in a synchronous context free grammar.  This approach of builds upon previous  The system described in this article performs compression on a sentence by sentence basis without any knowledge of the discourse structure or relation between 







{In order to arrive at suitable constraints for deletion, several approaches have been proposed. One example from \citep{Knight:2002:SBS:604203.604207} models compression as a translation from a verbose sentence to a sparse one. In this approach the noisy channel model is used to find the most likely compression out of a set of many possible compressions. In the paper by \citet{Clarke:2010:DCD:1950488.1950493} which I will be covering in section 2, the authors re-imagines the task as an optimization problem:  Given a string of text, retain the words which maximize a scoring function.  The scoring function is series of competing constraints, including rules about enforcing grammaticality, keeping text to a certain length, and retaining informative words based on sentence and discourse level information. 


}

\subsection{Simplification}


\subsection{Paraphrasing/Fusion}






\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{eule.png}
\caption{The saarland uni logo.}
\label{fig:logo}
\end{figure}

\lipsum[14-15]